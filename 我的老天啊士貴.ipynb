{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1.<b>前置作業</b> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 注意：要先載ckiptagger </h4>\n",
    "<ul>\n",
    "  <li> <a href=\"https://github.com/ckiplab/ckiptagger\">Github官方文檔</a></li>\n",
    "  <li> <a href=\"https://medium.com/@br19920702/%E4%B8%AD%E7%A0%94%E9%99%A2%E9%96%8B%E6%BA%90nlp%E5%A5%97%E4%BB%B6-ckiptagger-%E7%B9%81%E4%B8%AD%E4%B8%8D%E7%B5%90%E5%B7%B4-7822fc4efbf\">中文安裝教學</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from ckiptagger import WS, POS, NER\n",
    "ws = WS(\"./data\")\n",
    "\n",
    "all_small = pd.read_csv('./士貴/專案資料.csv',engine='python',encoding='utf-8',header=None,names=['日期','標題','內容'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2.<b>排除遺失值&選擇資料</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:#009933\"> >>優化點1：該用甚麼字篩出符合台積電的文章  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_small = all_small.dropna()\n",
    "GG = all_small[(all_small['內容'].str.contains('台積|面板|半導體|台G|GG|蘋概股|晶圓|奈米|製程|貿易戰|中美|大盤|美股|2330|川普')==True) & (all_small['標題'].str.contains('[公告]')==False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3.<b>確認迴圈時間</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date = list(set(GG['日期'].value_counts().index)) #抓出時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date.sort()       #讓資料照時間排\n",
    "Date = Date[1:]   #確保資料為5/29-11/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.<b>實作tf</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:#009933\">  >>優化點2：斷詞能否更準 (到最後他會存成很多csv，去預設資料夾看他切出的詞與分數，是還不錯但仍不好) </p>\n",
    "<p style=\"color:#009933\">  >>優化點3：tf-idf算法是否仍可改良？ 會不會導致重要的字反而分數較低？例如「開噴」，若每筆文章都提到，代表明天股價應該會下降，但idf會認為他在不同文章出現次數過高，反而使分數下降 </p>\n",
    "<p style=\"color:#009933\">  >>優化點4：我是以\"天\"為單位，把所有文章總和起來，給每天一個各詞的tf-idf值，所以和tf-idf原先的目的(找出能夠代表這篇文章的重要詞彙)並不相同 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【2019-05-29】\n",
      ">> 共有 7文章 / 259詞 / 403詞數\n",
      ">> 次數Dataframe完成\n",
      ">> tf矩陣完成\n",
      ">> idf矩陣完成\n",
      ">> tf-idf矩陣完成\n",
      ">>>>>> 結束並存檔 (共1.69秒)\n",
      "【2019-05-30】\n",
      ">> 共有 278文章 / 3907詞 / 16365詞數\n",
      ">> 次數Dataframe完成\n",
      ">> tf矩陣完成\n",
      ">> idf矩陣完成\n",
      ">> tf-idf矩陣完成\n",
      ">>>>>> 結束並存檔 (共84.15秒)\n"
     ]
    }
   ],
   "source": [
    "from ckiptagger import WS, POS, NER\n",
    "import time\n",
    "\n",
    "ws = WS(\"./data\")\n",
    "\n",
    "for date in Date[0:2]:\n",
    "    tStart = time.time()#計時開始\n",
    "    print('【'+date+'】')\n",
    "    \n",
    "    #第一部分： 【斷詞+計算當天詞集+計算當天出現詞數】\n",
    "    ### 詞數 v.s 詞集:  詞數可以重複，詞集不行  (例如 1th、3th文章都有 \"台積\" ， 那詞數會是 2個 、詞集會是 1個\n",
    "    ws_results = ws(GG[GG['日期']==date]['內容'],sentence_segmentation=False)\n",
    "    word_list = [] #出現詞數\n",
    "    word_set = []  #當天詞集\n",
    "    for article_nth in ws_results:\n",
    "        for word in article_nth :    \n",
    "            word_list.append(word)\n",
    "    word_set = list(set(word_list))\n",
    "    print('>> 共有 ' + str(len(ws_results)) + '文章'+ ' / ' + str(len(word_set)) + '詞' + ' / ' + str(len(word_list)) + '詞數')\n",
    "\n",
    "    #第二部ˋ分： 【創建空的Dataframe，欄位是當天有幾篇文章，列是當天的詞集數量】\n",
    "    zero_data = np.zeros(shape=(len(word_set),len(ws_results)))\n",
    "    globals()['columns'] = []\n",
    "    for col in range(len(ws_results)):\n",
    "        columns.append(str(col+1)+'th')\n",
    "    total = pd.DataFrame(zero_data,index=word_set,columns=columns)\n",
    "    check_word = list(total.index)\n",
    "    \n",
    "    ##算次數\n",
    "    for total_col in range(len(total.columns)):\n",
    "        for text_pos in ws_results[total_col]:\n",
    "            total.iloc[check_word.index(text_pos),total_col] +=1\n",
    "    print('>> 次數Dataframe完成')\n",
    "    \n",
    "    #深複製tf - idf\n",
    "    tf = copy.deepcopy(total)\n",
    "    idf = copy.deepcopy(total)\n",
    "    \n",
    "    #tf矩陣計算\n",
    "    for tf_col in range(len(tf.columns)):\n",
    "        col_sum = tf.sum(axis=0)[tf_col]\n",
    "        for tf_row in range(len(tf)):\n",
    "            if (tf.iloc[tf_row,tf_col] != 0):\n",
    "                tf.iloc[tf_row,tf_col] = round(tf.iloc[tf_row,tf_col]/col_sum,6)\n",
    "    print('>> tf矩陣完成')\n",
    "    \n",
    "    #idf矩陣成形\n",
    "    for idf_col in range(len(idf.columns)):\n",
    "        for idf_text_rol in idf.iloc[np.where(idf.iloc[:,idf_col]!=0)[0],:].index:\n",
    "            idf.iloc[np.where(idf.index==idf_text_rol)[0],idf_col]=(math.log(len(ws_results)/len(np.where(idf.loc[idf_text_rol]!=0)[0])))\n",
    "    print('>> idf矩陣完成')\n",
    "    \n",
    "    #tf idf互乘\n",
    "    tfidf = pd.DataFrame(np.array(tf)*np.array(idf),columns=columns,index=word_set)\n",
    "    print('>> tf-idf矩陣完成')\n",
    "    \n",
    "    #給出每天的 詞-tfidf分數 資料表\n",
    "    tfidf_text = pd.DataFrame(tfidf.sum(axis=1),columns=['分數']) #列總和\n",
    "    word = copy.deepcopy(tfidf_text.sort_values('分數',ascending=False).index)\n",
    "    score = copy.deepcopy(tfidf_text.sort_values('分數',ascending=False)['分數'])\n",
    "    pd.DataFrame({'詞':word,'分數':score}).to_csv(date+'.csv',encoding='utf_8_sig',index=False)\n",
    "    tEnd = time.time()#計時結束\n",
    "    print('>>>>>> 結束並存檔 (共' + str(round(tEnd-tStart,2)) + '秒)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
